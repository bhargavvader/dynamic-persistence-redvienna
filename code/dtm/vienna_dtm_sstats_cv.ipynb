{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qasgWzpAzBn8"
   },
   "source": [
    "### Vienna Analysis\n",
    "\n",
    "We will be analysing the texts from our Yearbooks, from 1870-2009. The data is already cleaned and organised, so the purpose of this notebook is to use this cleaned data to create the data structures we need for two kinds of analysis: an evolving dynamic topic model, and creating a word embedding model on the entire data set so that we can capture semantic ideaologies.\n",
    "\n",
    "1870–1913: pre Red Vienna (could start with 1890 to balance length of period)\n",
    "\n",
    "1918–1935: Red Vienna\n",
    "\n",
    "1946–1968: Reconstruction\n",
    "\n",
    "1969–1989: Iron curtain\n",
    "\n",
    "1990–2009: Postmodernity \n",
    "\n",
    "Dynamic Topic Models backwards - where do these topics come from?\n",
    "\n",
    "Move in fighting poverty from decentralised to centralised. \n",
    "\n",
    "#### Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PtYTaHkazBn_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5i5cHNeY3nCk",
    "outputId": "7c46d288-0c2b-4f88-ef2f-be14a9ad369a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "niEZvS1jzBoA"
   },
   "outputs": [],
   "source": [
    "docs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DvtLsVidzBoA"
   },
   "outputs": [],
   "source": [
    "with open('yearbooks_tibble_all.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        year, page, term, count, decade, total = row\n",
    "        if (year, page) not in docs:\n",
    "            docs[(year, page)] = []\n",
    "        if (year, page) in docs:\n",
    "            docs[(year, page)].append(term)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a-Nb31A9zBoB"
   },
   "outputs": [],
   "source": [
    "del docs[('year', 'page')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtGvLeaozBoB",
    "outputId": "7a87f178-e050-47ac-8fce-c1c101cb0399"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bauteil',\n",
       " 'bauwerk',\n",
       " 'bedeut',\n",
       " 'bett',\n",
       " 'doebling',\n",
       " 'fertigstell',\n",
       " 'gestieg',\n",
       " 'instandsetzungsarbeit',\n",
       " 'international',\n",
       " 'kirch',\n",
       " 'kultur',\n",
       " 'million',\n",
       " 'otto',\n",
       " 'renovi',\n",
       " 'schilling',\n",
       " 'stad',\n",
       " 'stadt',\n",
       " 'steinhof',\n",
       " 'studentenheim',\n",
       " 'volksbild',\n",
       " 'vorgeseh',\n",
       " 'wagn',\n",
       " 'zweit']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[('1970', '56')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-ISR3pyzBoD"
   },
   "source": [
    "### Dynamic Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJWJjs_CzBoD"
   },
   "source": [
    "1870–1913: pre Red Vienna (could start with 1890 to balance length of period)\n",
    "\n",
    "1918–1935: Red Vienna\n",
    "\n",
    "1946–1968: Reconstruction\n",
    "\n",
    "1969–1989: Iron curtain\n",
    "\n",
    "1990–2009: Postmodernity \n",
    "\n",
    "#### New time periods\n",
    "\n",
    "1870-1880\n",
    "\n",
    "1881-1895\n",
    "\n",
    "1896-1902\n",
    "\n",
    "1903-1908\n",
    "\n",
    "1909-1913\n",
    "\n",
    "1918-1935\n",
    "\n",
    "1946-1954\n",
    "\n",
    "1955-1959\n",
    "\n",
    "1960-1964\n",
    "\n",
    "1965-1968\n",
    "\n",
    "1969-1979\n",
    "\n",
    "1980-1989\n",
    "\n",
    "1990-1996\n",
    "\n",
    "1997-2009\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a88rv6ruzBoD"
   },
   "outputs": [],
   "source": [
    "# timed_docs = [[], [], [], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vn36QKHOzBoE"
   },
   "outputs": [],
   "source": [
    "# for doc in docs:\n",
    "#     year, page = doc\n",
    "#     if int(year) >= 1870 and int(year) <=1913:\n",
    "#         timed_docs[0].append(docs[doc])\n",
    "#     if int(year) >= 1918 and int(year) <=1935:\n",
    "#         timed_docs[1].append(docs[doc])\n",
    "#     if int(year) >= 1946 and int(year) <=1968:\n",
    "#         timed_docs[2].append(docs[doc])\n",
    "#     if int(year) >= 1969 and int(year) <=1989:\n",
    "#         timed_docs[3].append(docs[doc])\n",
    "#     if int(year) >= 1990 and int(year) <=2009:\n",
    "#         timed_docs[4].append(docs[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 time periods\n",
    "timed_docs = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    year, page = doc\n",
    "    if int(year) >= 1870 and int(year) <=1880:\n",
    "        timed_docs[0].append(docs[doc])\n",
    "    if int(year) >= 1881 and int(year) <=1895:\n",
    "        timed_docs[1].append(docs[doc])\n",
    "    if int(year) >= 1896 and int(year) <=1902:\n",
    "        timed_docs[2].append(docs[doc])\n",
    "    if int(year) >= 1903 and int(year) <=1908:\n",
    "        timed_docs[3].append(docs[doc])\n",
    "    if int(year) >= 1909 and int(year) <=1913:\n",
    "        timed_docs[4].append(docs[doc])\n",
    "    if int(year) >= 1918 and int(year) <=1935:\n",
    "        timed_docs[5].append(docs[doc])\n",
    "    if int(year) >= 1946 and int(year) <=1954:\n",
    "        timed_docs[6].append(docs[doc])\n",
    "    if int(year) >= 1955 and int(year) <=1959:\n",
    "        timed_docs[7].append(docs[doc])\n",
    "    if int(year) >= 1960 and int(year) <=1964:\n",
    "        timed_docs[8].append(docs[doc])\n",
    "    if int(year) >= 1965 and int(year) <=1968:\n",
    "        timed_docs[9].append(docs[doc])\n",
    "    if int(year) >= 1969 and int(year) <=1979:\n",
    "        timed_docs[10].append(docs[doc])\n",
    "    if int(year) >= 1980 and int(year) <=1989:\n",
    "        timed_docs[11].append(docs[doc])\n",
    "    if int(year) >= 1990 and int(year) <=1996:\n",
    "        timed_docs[12].append(docs[doc])\n",
    "    if int(year) >= 1997 and int(year) <=2009:\n",
    "        timed_docs[13].append(docs[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ftt', 'stadt', 'verwalt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timed_docs[13][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['herausgegeb', 'stadt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timed_docs[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kis', 'len', 'oie', 'rot', 'uli', 'uni', 'vei']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timed_docs[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-jxK9HDmzBoE"
   },
   "outputs": [],
   "source": [
    "final_docs = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Kseo8sF-zBoF"
   },
   "outputs": [],
   "source": [
    "for period in timed_docs:\n",
    "    times.append(len(period))\n",
    "    for doc in period:\n",
    "        final_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9-jaen45zBoF"
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaSeqModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zmPbhmIizBoG"
   },
   "outputs": [],
   "source": [
    "# bigram = gensim.models.Phrases(final_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Z52sIgu7zBoG"
   },
   "outputs": [],
   "source": [
    "# texts = [bigram[line] for line in final_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "puwxABF_zBoG"
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(final_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in final_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178872"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards Model with Sufficient Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq_fast = LdaSeqModel.load(\"ldaseq_rev_fast_32_14periods_CV001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstats = ldaseq_fast.sstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dIKhMZWfzBoJ"
   },
   "outputs": [],
   "source": [
    "rev_corpus = list(reversed(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TZW_FUnGzBoJ"
   },
   "outputs": [],
   "source": [
    "rev_times = list(reversed(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWxw_aZ6zBoK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brsiniva/Downloads/venv/lib/python3.9/site-packages/gensim/models/ldaseqmodel.py:298: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "ldaseq_rev = LdaSeqModel(corpus=rev_corpus, id2word=dictionary, time_slice=rev_times, num_topics=32, chunksize=1, chain_variance=0.05, initialize='own', sstats=sstats, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq_rev.save(\"ldaseq_32_topics_14_periods_reverse_cv005\") # 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZmkVfBpzBoK"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev_fast = LdaSeqModel(corpus=rev_corpus, id2word=dictionary, time_slice=rev_times, num_topics=5, chunksize=1, chain_variance=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "no3GaKH4zBoK"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev.print_topics(time=0)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlMIMT3tzBoK"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev.print_topics(time=3)[9]po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkxB5V88zBoK"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev_fast.print_topics(time=0)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DJFwv-6zBoL"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev_fast.print_topics(time=3)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzb71cC0zBoL"
   },
   "outputs": [],
   "source": [
    "# ldaseq.save(\"ldaseq_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6t3R5L_mzBoL"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev.save(\"ldaseq_rev_5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2M0_xsezBoL"
   },
   "outputs": [],
   "source": [
    "# ldaseq_fast.save(\"ldaseq_fast_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kT5MuJfgzBoL"
   },
   "outputs": [],
   "source": [
    "# ldaseq_rev_fast.save(\"ldaseq_rev_fast_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dtm = ldaseq.dtm_coherence(time=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_DTM = CoherenceModel(topics=topics_dtm, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"DTM Python coherence is\", cm_DTM.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pickle.load(open('Corpus/texts', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_DTM = CoherenceModel(topics=topics_dtm, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"DTM Python coherence is\", cm_DTM.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German to English dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDiF6MrFzBoM"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65iFSwckzBoM"
   },
   "outputs": [],
   "source": [
    "ger_to_eng = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cN9kMz6_zBoM"
   },
   "outputs": [],
   "source": [
    "with open('yearbooksGERtoENG.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        ger, eng = row\n",
    "        ger_to_eng[ger] = eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkULEecZzBoM"
   },
   "outputs": [],
   "source": [
    "missing_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmXrb-QFzBoM"
   },
   "outputs": [],
   "source": [
    "for doc in final_docs:\n",
    "    for word in doc:\n",
    "        if word not in ger_to_eng and word not in missing_words:\n",
    "            missing_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtbfjZzXzBoN",
    "outputId": "5bd2946d-f7e7-4c59-d5df-e7bfd91cf744"
   },
   "outputs": [],
   "source": [
    "missing_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EahrN1cIzBoN"
   },
   "outputs": [],
   "source": [
    "def topics_in_english(topic_model, topic_number, time_slice):\n",
    "    words  = topic_model.print_topics(time=time_slice)[topic_number]\n",
    "    eng_words = []\n",
    "    for word in words:\n",
    "        ger_word, proportion = word\n",
    "        try:\n",
    "            eng_words.append((ger_to_eng[ger_word], proportion))\n",
    "        except KeyError:\n",
    "            eng_words.append((ger_word, proportion))            \n",
    "    return eng_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u46DITZxzBoN",
    "outputId": "62717a39-6f96-484a-a79d-c52026dcdf12"
   },
   "outputs": [],
   "source": [
    "len(ger_to_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auzBFpt3zBoN",
    "outputId": "3fd5ddfe-ff78-42f9-b60a-050f643f5a74"
   },
   "outputs": [],
   "source": [
    "topics_in_english(ldaseq_fast, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4zjB5uhzBoO",
    "outputId": "f58a1de1-3d76-4cfe-8a60-b149f0ab6e76"
   },
   "outputs": [],
   "source": [
    "topics_in_english(ldaseq_fast, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJL6M6_8zBoO"
   },
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8fmdruxzBoO"
   },
   "outputs": [],
   "source": [
    "def tracking_change(topic_model, topic_num, first_time_period=0, second_time_period=4):\n",
    "    \n",
    "    topics_begin = topic_model.print_topics(time=first_time_period)[topic_num]\n",
    "    topics_end = topic_model.print_topics(time=second_time_period)[topic_num]\n",
    "    \n",
    "    word_ranks_begin = {}\n",
    "    word_ranks_end = {}\n",
    "    word_change = {}\n",
    "    words_begin, words_end = [], []\n",
    "    \n",
    "    for num, word_prob in enumerate(topics_begin):\n",
    "        word, prob = word_prob\n",
    "        word_ranks_begin[word] = num\n",
    "        words_begin.append(word)\n",
    "            \n",
    "    for num, word_prob in enumerate(topics_end):\n",
    "        word, prob = word_prob\n",
    "        word_ranks_end[word] = num\n",
    "        words_end.append(word)\n",
    "\n",
    "    for word in words_begin:\n",
    "        if word not in word_ranks_end:\n",
    "            word_ranks_end[word] = 21\n",
    "    \n",
    "    for word in words_end:\n",
    "        if word not in word_ranks_begin:\n",
    "            word_ranks_begin[word] = 21\n",
    "    \n",
    "    all_words = list(set(words_begin) | set(words_end)) \n",
    "    \n",
    "    for word in all_words:\n",
    "        word_change[word] = word_ranks_begin[word] - word_ranks_end[word]\n",
    "\n",
    "    \n",
    "    sorted_word_change = sorted(word_change.items(), key=operator.itemgetter(1))\n",
    "    \n",
    "    sorted_word_change.reverse()\n",
    "    \n",
    "    return sorted_word_change\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQ_Xyw94zBoO"
   },
   "outputs": [],
   "source": [
    "# change here to track prevalance. since there are so many words, the word change probabilities are not super useful... yet.\n",
    "def tracking_change_prevalance(topic_model, topic_num, first_time_period=0, second_time_period=4):\n",
    "    \n",
    "    topics_begin = topic_model.print_topics(time=first_time_period)[topic_num]\n",
    "    topics_end = topic_model.print_topics(time=second_time_period)[topic_num]\n",
    "    \n",
    "    word_prevalance_begin = {}\n",
    "    word_prevalance_end = {}\n",
    "    word_change = {}\n",
    "    words_begin, words_end = [], []\n",
    "    all_probs = []\n",
    "    \n",
    "    for num, word_prob in enumerate(topics_begin):\n",
    "        word, prob = word_prob\n",
    "        word_prevalance_begin[word] = prob\n",
    "        words_begin.append(word)\n",
    "        all_probs.append(prob)\n",
    "        \n",
    "    for num, word_prob in enumerate(topics_end):\n",
    "        word, prob = word_prob\n",
    "        word_prevalance_end[word] = prob\n",
    "        words_end.append(word)\n",
    "        all_probs.append(prob)\n",
    "    \n",
    "    min_prob = min(all_probs)\n",
    "    \n",
    "    for word in words_begin:\n",
    "        if word not in word_prevalance_end:\n",
    "            word_prevalance_end[word] = min_prob\n",
    "    \n",
    "    for word in words_end:\n",
    "        if word not in word_prevalance_begin:\n",
    "            word_prevalance_begin[word] = min_prob\n",
    "    \n",
    "    all_words = list(set(words_begin) | set(words_end)) \n",
    "    \n",
    "    for word in all_words:\n",
    "        word_change[word] = word_prevalance_end[word] - word_prevalance_begin[word]\n",
    "\n",
    "    \n",
    "    sorted_word_change = sorted(word_change.items(), key=operator.itemgetter(1))\n",
    "    \n",
    "    sorted_word_change.reverse()\n",
    "    \n",
    "    return sorted_word_change\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFaJnHmxzBoP",
    "outputId": "9da8df9d-7e69-45fd-d6c1-169050620f33"
   },
   "outputs": [],
   "source": [
    "tracking_change_prevalance(ldaseq_rev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLw_bx-PzBoP",
    "outputId": "2f2cf8e2-2347-4ee3-f970-7251809148c7"
   },
   "outputs": [],
   "source": [
    "tracking_change(ldaseq_rev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxMUt6k2zBoP",
    "outputId": "542430b3-3e1b-4746-99c0-4394b204421d"
   },
   "outputs": [],
   "source": [
    "tracking_change(ldaseq_rev_fast, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GI48_vpzBoP"
   },
   "outputs": [],
   "source": [
    "def doc_topic_proportions(corpus, model, times, no_topics):\n",
    "    \n",
    "    max_proportions = {}\n",
    "    \n",
    "    for num, doc in enumerate(corpus):\n",
    "        topic_proportions = model[doc]\n",
    "        topics = np.nonzero(topic_proportions > 0.33)\n",
    "        max_proportions[num] = topics[0]\n",
    "        \n",
    "    ranges = [0]\n",
    "    for num in np.cumsum(times):\n",
    "        ranges.append(num)\n",
    "    \n",
    "    time_period_counts = {}\n",
    "    for i in range(0, len(times)):\n",
    "        time_period_counts[i] = np.zeros(no_topics)\n",
    "        \n",
    "    for doc in max_proportions:\n",
    "        if doc < ranges[1] and doc > ranges[0]:\n",
    "            for val in max_proportions[doc]:\n",
    "                time_period_counts[0][val] += 1\n",
    "        if doc < ranges[2] and doc > ranges[1]:\n",
    "            for val in max_proportions[doc]:\n",
    "                time_period_counts[1][val] += 1\n",
    "        if doc < ranges[3] and doc > ranges[2]:\n",
    "            for val in max_proportions[doc]:\n",
    "                time_period_counts[2][val] += 1\n",
    "        if doc < ranges[4] and doc > ranges[3]:\n",
    "            for val in max_proportions[doc]:\n",
    "                time_period_counts[3][val] += 1\n",
    "        if doc < ranges[5] and doc > ranges[4]:\n",
    "            for val in max_proportions[doc]:\n",
    "                time_period_counts[4][val] += 1\n",
    "    \n",
    "    time_period_proportions = {}\n",
    "\n",
    "    for time in time_period_counts:\n",
    "        time_period_proportions[time] = np.round(time_period_counts[time] / np.sum(time_period_counts[time]), 2)\n",
    "\n",
    "    return time_period_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDbKPonOzBoQ"
   },
   "outputs": [],
   "source": [
    "time_period_proportions = doc_topic_proportions(corpus, ldaseq_fast, times, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MV6NRYAzzBoQ",
    "outputId": "0079dcb9-4d66-461b-ee05-96b5bb91bf2b"
   },
   "outputs": [],
   "source": [
    "time_period_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions  = {0: [0.15789474, 0.23578947, 0.06736842, 0.07368421, 0.46526316],\n",
    " 1: [0.225     , 0.35416667, 0.1625    , 0.15833333, 0.1       ],\n",
    " 2: [0.2034384 , 0.33524355, 0.15186246, 0.20630372, 0.10315186],\n",
    " 3: [0.26519337, 0.32596685, 0.12707182, 0.15469613, 0.12707182],\n",
    " 4: [0.25096525, 0.36679537, 0.17760618, 0.11583012, 0.08880309]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(proportions[0], proportions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(proportions[3], proportions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAAGBg2XzBoQ",
    "outputId": "ef468649-1cce-463a-8aa6-521f8d335e39"
   },
   "outputs": [],
   "source": [
    "ldaseq_fast.print_topics(time=4)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1MPI20zzBoQ",
    "outputId": "3027d2f2-3eb3-49f8-a0af-1d49896a28c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracking_change(ldaseq_fast, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models and Word Change to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq_fast = LdaSeqModel.load(\"ldaseq_fast_filtered_2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "p02KqBABzBoR"
   },
   "outputs": [],
   "source": [
    "# change here to include all time periods in a single file\n",
    "def topics_to_csv(model, name_file, times=14):\n",
    "    with open(name_file, 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile)\n",
    "        for time in range(0, times):\n",
    "            spamwriter.writerow([\"Topic Number for time period \" + str(time) , \"Word, Probability\"])\n",
    "            topics = model.print_topics(time=time)\n",
    "            for num, topic in enumerate(topics):\n",
    "                topic.insert(0, num)\n",
    "                spamwriter.writerow(topic)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vqmtkoRTzBoR"
   },
   "outputs": [],
   "source": [
    "topics_to_csv(ldaseq, \"ldaseq_16_topics_14_periods_unfiltered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_to_csv(ldaseq_rev, \"ldaseq_24_topics_14_periods_unfiltered_reverse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSST_FIdzBoR"
   },
   "outputs": [],
   "source": [
    "# change here to include time periods of choice: default is between first and last (i.e 0 and 4)\n",
    "def change_to_csv(model, name_file, num_of_topics=7, first_time_period=0, second_time_period=4):\n",
    "    with open(name_file, 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile)\n",
    "        spamwriter.writerow([\"Topic Number\", \"Word, Change\"])\n",
    "        for i in range(0, num_of_topics):\n",
    "            changes = tracking_change(model, i, first_time_period=first_time_period, second_time_period=second_time_period)\n",
    "            changes.insert(0, i)\n",
    "            spamwriter.writerow(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHYvnCaSzBoR"
   },
   "outputs": [],
   "source": [
    "# new format to match what wanted\n",
    "def change_to_csv_advanced(model, name_file, num_of_topics=7, first_time_period=0, second_time_period=4):\n",
    "    with open(name_file, 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile)\n",
    "        spamwriter.writerow([\"Topic Number\", \"Deutsch\", \"Rank\", \"English\"])\n",
    "        for i in range(0, num_of_topics):\n",
    "            changes = tracking_change(model, i, first_time_period=first_time_period, second_time_period=second_time_period)\n",
    "#             changes.insert(0, i)\n",
    "            for word_rank in changes:\n",
    "                word, rank = word_rank\n",
    "                try:\n",
    "                    spamwriter.writerow([\"Topic \" + str(i), word, rank, ger_to_eng[word]])\n",
    "                except KeyError:\n",
    "                    spamwriter.writerow([\"Topic \" + str(i), word, rank, word])\n",
    "#                 spamwriter.writerow(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HABuzsWUzBoS"
   },
   "outputs": [],
   "source": [
    "change_to_csv_advanced(ldaseq, \"ldaseq_changes_12topics_new.csv\", num_of_topics=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_to_csv_advanced(ldaseq_fast, \"ldaseq_fast_changes_12topics_all.csv\", num_of_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4mTJKTszBoS"
   },
   "outputs": [],
   "source": [
    "change_to_csv(ldaseq_fast, \"ldaseq_fast_changes_5topics.csv\", num_of_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIQ9Pe44zBoS"
   },
   "outputs": [],
   "source": [
    "# tracking change in prevelance from period to period"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "vienna_dtm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
